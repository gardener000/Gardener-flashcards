// data/os_main_mem.js
export default {
  name: "操作系统：主存管理",
  data: [
    {front:"主存管理的核心问题是什么？🧠", back:`<dl><dt>速度矛盾</dt><dd>CPU 速度远超主存 (RAM)，直接访问会造成 <mark>CPU 空闲等待</mark>，浪费性能。</dd><dt>内存层级 (Memory Hierarchy)</dt><dd>通过引入 <mark>高速缓存 (Cache)</mark> 解决速度问题。<br>层级结构为：寄存器 > 缓存 > 主存 > 磁盘。</dd><dt>核心原则</dt><dd>程序运行前必须从 <mark>磁盘 (Disk)</mark> 加载到 <mark>主存 (Memory)</mark> 中，并且需要内存 <mark>保护 (Protection)</mark> 机制防止进程间干扰。</dd></dl>`},
    {front:"逻辑地址 vs 物理地址 & 地址绑定 🗺️", back:`<dl><dt>逻辑地址 (Logical Address)</dt><dd>由 CPU 生成，也称<mark>虚拟地址</mark>。是程序视角下的地址，通常从 0 开始且连续。</dd><dt>物理地址 (Physical Address)</dt><dd>内存硬件实际使用的地址。</dd><dt>地址绑定 (Binding)</dt><dd>将逻辑地址映射到物理地址。可在 <mark>编译时</mark>、<mark>加载时</mark> 或 <mark>运行时</mark> 进行。现代系统普遍采用 <mark>运行时绑定</mark> 以获得最大灵活性。</dd><dt>MMU (内存管理单元)</dt><dd>执行 <mark>运行时绑定</mark> 的硬件，通过 <mark>基址/重定位寄存器 (Base/Relocation Register)</mark> 实现动态地址转换。</dd></dl>`},
    {front:"连续内存分配 & 碎片问题 🧱", back:`<dl><dt>核心思想</dt><dd>为每个进程分配一块 <mark>连续的</mark> 内存空间。</dd><dt>动态分配策略</dt><dd><b>首次适应 (First-fit):</b> 找到第一个足够大的空闲块。<br><b>最佳适应 (Best-fit):</b> 找到最小的足够大的空闲块。<br><b>最差适应 (Worst-fit):</b> 找到最大的空闲块。</dd><dt>碎片 (Fragmentation)</dt><dd><b>外部碎片:</b> 总内存空间足够，但分散的小块无法满足请求。<br><b>内部碎片:</b> 分配的内存块大于请求大小，块内产生浪费。</dd><dt>解决方案</dt><dd>通过 <mark>紧凑 (Compaction)</mark> 解决外部碎片，但开销大。更好的方法是采用非连续分配。</dd></dl>`},
    {front:"分页 (Paging) 的核心原理 📖", back:`<dl><dt>核心思想</dt><dd>物理内存划分为固定大小的 <mark>帧 (Frame)</mark>，逻辑内存划分为同样大小的 <mark>页 (Page)</mark>。</dd><dt>地址转换</dt><dd>逻辑地址分为 <mark>页号 (p)</mark> 和 <mark>页内偏移 (d)</mark>。通过 <mark>页表 (Page Table)</mark> 查找页号 p 对应的帧号 f，最终物理地址由 f 和 d 组合而成。</dd><dt>优点</dt><dd>完全消除 <mark>外部碎片</mark>，分配灵活。</dd><dt>缺点</dt><dd>会产生少量 <mark>内部碎片</mark> (在最后一页)。</dd></dl>`},
    {front:"如何优化分页的性能？🚀 (TLB)", back:`<dl><dt>性能瓶颈</dt><dd>标准分页每次访存需要 <mark>两次内存访问</mark>：一次查页表，一次访问真实数据。</dd><dt>解决方案: TLB</dt><dd>引入 <mark>旁路转换缓冲 (Translation Look-aside Buffer, TLB)</mark>，一个页表项的高速硬件缓存 (也叫“快表”)。</dd><dt>工作流程</dt><dd>CPU 生成地址后先查 TLB：<br><b>命中 (Hit):</b> 极速获取帧号，只需一次内存访问。<br><b>未命中 (Miss):</b> 正常查询主存页表，并将结果存入 TLB 供后续使用。</dd><dt>效果</dt><dd>利用 <mark>局部性原理</mark>，TLB 命中率极高 (如98%)，使有效访问时间 (EAT) 接近一次内存访问。</dd></dl>`},
    {front:"页表太大怎么办？(页表结构) 🏛️", back:`<dl><dt>问题</dt><dd>在 64 位系统中，简单的线性页表会变得异常巨大，无法存入内存。</dd><dt>分层分页 (Hierarchical Paging)</dt><dd>将页表本身也进行分页，形成 <mark>二级或多级页表</mark>。优点是只需为实际使用的地址空间分配页表，节省大量空间。</dd><dt>哈希页表 (Hashed Page Table)</dt><dd>处理稀疏地址空间，将虚拟页号哈希到哈希表中，通过链表解决冲突。</dd><dt>反向页表 (Inverted Page Table)</dt><dd>全局仅一张表，每个 <mark>物理帧</mark> 对应一个表项。页表大小与物理内存相关，与逻辑地址空间无关，极大节省空间，但查找复杂。</dd></dl>`},
    {front:"分段 (Segmentation) 的核心原理 📂", back:`<dl><dt>核心思想</dt><dd>从 <mark>程序员视角</mark> 出发，将程序划分为多个有逻辑意义的 <mark>段 (Segment)</mark>，如代码段、数据段、堆栈段。</dd><dt>逻辑地址</dt><dd>是一个二维结构：<mark><段号, 段内偏移></mark>。</dd><dt>段表 (Segment Table)</dt><dd>每个条目包含段的 <mark>基址 (base)</mark> 和 <mark>界限 (limit)</mark>，用于地址转换和保护。</dd><dt>优缺点</dt><dd><b>优点:</b> 保护和共享非常直观自然。<br><b>缺点:</b> 段大小可变，会重新引入 <mark>外部碎片</mark> 问题。</dd></dl>`},
    {front:"段页式管理 (Segmentation with Paging) 🏆", back:`<dl><dt>核心思想</dt><dd>结合分段和分页的优点，<mark>取长补短</mark>。对外呈现分段的逻辑视图，对内通过分页管理物理内存。</dd><dt>结构</dt><dd>每个逻辑 <mark>段</mark> 拥有自己的 <mark>页表</mark>。内存被划分为页，段被映射到这些离散的页中。</dd><dt>地址转换</dt><dd>逻辑地址 → (查段表) → 找到对应页表 → (查页表) → 找到物理帧 → 形成物理地址。</dd><dt>应用</dt><dd><mark>Intel x86</mark> 架构是其经典实现。现代 Linux 为了简化和可移植性，则弱化分段功能，主要依赖强大的多级分页机制。</dd></dl>`},
    {front:"内存优化技术速记 💡", back:`<dl><dt>交换 (Swapping)</dt><dd>将整个进程暂时从内存移出到 <mark>后备存储 (Backing Store)</mark>，以释放空间。是虚拟内存的基础。</dd><dt>动态加载 (Dynamic Loading)</dt><dd>程序模块 (如函数) 在被调用时才加载到内存，提高内存利用率。</dd><dt>动态链接 (Dynamic Linking)</dt><dd>链接过程推迟到运行时。多个进程可共享一份库代码 (<mark>共享库</mark>，如 .dll, .so)，极大节省内存。</dd><dt>内存保护 (Protection)</dt><dd>通过 <mark>基址/界限寄存器</mark> (分段/连续分配) 或 <mark>有效-无效位 (Valid-Invalid Bit)</mark> (分页) 防止进程访问非法内存。</dd></dl>`}
  ]
};